{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_object_detection_training_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karat-GS/object_detection_demo/blob/karat/tensorflow_object_detection_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25bb010d-hLb",
        "colab_type": "text"
      },
      "source": [
        "## Config tf version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23nFTvH-TrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2fa77f0-2ab5-424e-d2f2-ae468898e181"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1",
        "colab_type": "text"
      },
      "source": [
        "## Clone the `object_detection_demo` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d7e3956c-a246-449a-8563-c44e1240fbe9"
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/Karat-GS/object_detection_demo'\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'object_detection_demo'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 879 (delta 11), reused 3 (delta 1), pack-reused 861\u001b[K\n",
            "Receiving objects: 100% (879/879), 749.53 MiB | 15.79 MiB/s, done.\n",
            "Resolving deltas: 100% (420/420), done.\n",
            "Checking out files: 100% (761/761), done.\n",
            "/content/object_detection_demo\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "43b37f25-fcb7-49cb-c4f1-c15dd84ecc79"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "!pip install git+https://github.com/google-research/tf-slim # pip install tf_slim\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n",
            "Collecting git+https://github.com/google-research/tf-slim\n",
            "  Cloning https://github.com/google-research/tf-slim to /tmp/pip-req-build-4dimg2r9\n",
            "  Running command git clone -q https://github.com/google-research/tf-slim /tmp/pip-req-build-4dimg2r9\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf-slim==1.2.0) (1.12.0)\n",
            "Building wheels for collected packages: tf-slim\n",
            "  Building wheel for tf-slim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-slim: filename=tf_slim-1.2.0-cp36-none-any.whl size=360912 sha256=89b3b1c9dabb3a600e09c641a4d909f7afb98dd8e57923dd1468f6ad87a06016\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w3za9ch9/wheels/bb/98/dc/eba6500d756d16f6ff371b39ed733d26cec1b0b0085e1cb0df\n",
            "Successfully built tf-slim\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training steps.\n",
        "num_steps = 3000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v3_large': {\n",
        "        'model_name': 'ssd_mobilenet_v3_large_coco_2020_01_14',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v3_large_320x320_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobiledet_edgetpu': {\n",
        "        'model_name': 'ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_edgetpu_320x320_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobiledet_edgetpu_quant': {\n",
        "        'model_name': 'ssdlite_mobilenet_edgetpu_coco_quant',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_edgetpu_320x320_coco_quant.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_v2_mnasfpn': {\n",
        "        'model_name': 'ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync_2020_05_18',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobiledet_cpu': {\n",
        "        'model_name': 'ssdlite_mobiledet_cpu_320x320_coco_2020_05_19',\n",
        "        'pipeline_file': 'ssdlite_mobiledet_cpu_320x320_coco_sync_4x4.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v3_large'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezGDABRXXhPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "bb2c5f51-7313-4198-c2c9-ea9a5f99f420"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "#!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "os.makedirs(os.path.dirname(\"data/annotations/\"), exist_ok=True)\n",
        "!cp \"data/conedPath/label_map.pbtxt\" \"data/annotations/\"\n",
        "!cp \"data/conedPath/train_labels.csv\" \"data/annotations/\"\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "#!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "!cp \"data/conedPath/test_labels.csv\" \"data/annotations/\"\n",
        "\n",
        "# Generate `train.record`\n",
        "#!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/conedPath/Dataset/PNGImages --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/conedPath/Dataset/PNGImages --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/object_detection_demo\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0701 21:32:43.631485 140258552510336 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0701 21:32:43.706631 140258552510336 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0701 21:32:49.460064 140716466014080 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0701 21:32:49.502198 140716466014080 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
        "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9816e15-0af3-4eab-c2b9-02040a1a75c6"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "44ab4609-88ef-4db5-f4e2-65c52086159e"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 58M\n",
            "drwxr-xr-t  2 382342 89939 4.0K Jan 15 22:36 .\n",
            "drwxr-xr-x 63 root   root  4.0K Jul  1 21:32 ..\n",
            "-rw-r--r--  1 382342 89939   77 Jan 15 22:35 checkpoint\n",
            "-rw-r--r--  1 382342 89939  13M Jan 15 22:35 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 382342 89939  25M Jan 15 22:35 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 382342 89939  12K Jan 15 22:35 model.ckpt.index\n",
            "-rw-r--r--  1 382342 89939 7.3M Jan 15 22:36 model.ckpt.meta\n",
            "-rw-r--r--  1 382342 89939  13M Jan 15 22:36 model.tflite\n",
            "-rw-r--r--  1 382342 89939 4.7K Jan 15 22:36 pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c2adca36-608a-4ce5-c941-4b6a96860a12"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87f0b929-a371-44ba-be71-324b15914e85"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSDLite with Mobilenet v3 large feature extractor.\n",
            "# Trained on COCO14, initialized from scratch.\n",
            "# 3.22M parameters, 1.02B FLOPs\n",
            "# TPU-compatible.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 2\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 320\n",
            "        width: 320\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.97,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v3_large'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      use_depthwise: true\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.97,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.75,\n",
            "          gamma: 2.0\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "          delta: 1.0\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: true\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 32\n",
            "  num_steps: 3000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.4\n",
            "          total_steps: 400000\n",
            "          warmup_learning_rate: 0.13333\n",
            "          warmup_steps: 2000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF",
        "colab_type": "text"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "fc05ef86-13ef-42f2-8913-45b69896e939"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-01 22:25:30--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.54.251.217, 54.159.115.94, 3.212.40.153, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.54.251.217|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  5.51MB/s    in 2.4s    \n",
            "\n",
            "2020-07-01 22:25:33 (5.51 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp",
        "colab_type": "text"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e942900-a0b3-472e-eed2-f66d0221a2b2"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://415a84682321.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2f3aeaf-9b8f-4001-b157-bebf4dc4193c"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}\n",
        "\n",
        "# Legacy way of training(also works)\n",
        "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0701 22:27:01.971967 140494240802688 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 3000\n",
            "I0701 22:27:01.972208 140494240802688 config_util.py:552] Maybe overwriting train_steps: 3000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0701 22:27:01.972312 140494240802688 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0701 22:27:01.972398 140494240802688 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0701 22:27:01.972483 140494240802688 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0701 22:27:01.972561 140494240802688 config_util.py:552] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0701 22:27:01.972636 140494240802688 config_util.py:562] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0701 22:27:01.973528 140494240802688 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0701 22:27:01.973651 140494240802688 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc71519d1d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0701 22:27:01.974112 140494240802688 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc71519d1d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc6f4a7abf8>) includes params argument, but params are not passed to Estimator.\n",
            "W0701 22:27:01.974335 140494240802688 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc6f4a7abf8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0701 22:27:01.975068 140494240802688 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0701 22:27:01.975254 140494240802688 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0701 22:27:01.975476 140494240802688 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0701 22:27:01.981663 140494240802688 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0701 22:27:02.013763 140494240802688 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0701 22:27:02.018782 140494240802688 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0701 22:27:02.038861 140494240802688 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc6f4a04978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0701 22:27:02.076593 140494240802688 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc6f4a04978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fc71a5a9488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0701 22:27:02.251660 140494240802688 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fc71a5a9488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0701 22:27:02.256952 140494240802688 deprecation.py:323] From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0701 22:27:02.264089 140494240802688 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0701 22:27:02.344505 140494240802688 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0701 22:27:03.182396 140494240802688 deprecation.py:323] From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 22:27:03.576805 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0701 22:27:03.587688 140494240802688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:27:06.020310 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:27:06.103343 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:27:06.198091 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:27:06.285662 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:27:06.514639 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:27:06.603032 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 22:27:12.462188 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0701 22:27:12.463485 140494240802688 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0701 22:27:14.754767 140494240802688 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-01 22:27:14.755158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-01 22:27:14.759852: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2020-07-01 22:27:14.760026: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10bc56c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-01 22:27:14.760057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-01 22:27:14.779247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-01 22:27:14.862804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:27:14.863275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10bc5500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-01 22:27:14.863305: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-07-01 22:27:14.863523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:27:14.863868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 22:27:14.864214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 22:27:14.865766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 22:27:14.867296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 22:27:14.867639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 22:27:14.869109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 22:27:14.869902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 22:27:14.873036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 22:27:14.873159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:27:14.873573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:27:14.873917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 22:27:14.873991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 22:27:14.875127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 22:27:14.875156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 22:27:14.875168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 22:27:14.875300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:27:14.875717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:27:14.876085: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-01 22:27:14.876134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0701 22:27:17.484596 140494240802688 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0701 22:27:17.703894 140494240802688 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0701 22:27:23.823856 140494240802688 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-07-01 22:27:30.006510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 22:27:44.442803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 35.663033, step = 0\n",
            "I0701 22:27:47.236088 140494240802688 basic_session_run_hooks.py:262] loss = 35.663033, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.20714\n",
            "I0701 22:29:10.075755 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.20714\n",
            "INFO:tensorflow:loss = 4.000984, step = 100 (82.911 sec)\n",
            "I0701 22:29:10.146669 140494240802688 basic_session_run_hooks.py:260] loss = 4.000984, step = 100 (82.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25986\n",
            "I0701 22:30:29.449624 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25986\n",
            "INFO:tensorflow:loss = 3.515699, step = 200 (79.304 sec)\n",
            "I0701 22:30:29.450918 140494240802688 basic_session_run_hooks.py:260] loss = 3.515699, step = 200 (79.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.26137\n",
            "I0701 22:31:48.728347 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.26137\n",
            "INFO:tensorflow:loss = 4.6204214, step = 300 (79.279 sec)\n",
            "I0701 22:31:48.729497 140494240802688 basic_session_run_hooks.py:260] loss = 4.6204214, step = 300 (79.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24918\n",
            "I0701 22:33:08.781242 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.24918\n",
            "INFO:tensorflow:loss = 3.058556, step = 400 (80.108 sec)\n",
            "I0701 22:33:08.837768 140494240802688 basic_session_run_hooks.py:260] loss = 3.058556, step = 400 (80.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.26873\n",
            "I0701 22:34:27.600141 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.26873\n",
            "INFO:tensorflow:loss = 2.8681548, step = 500 (78.764 sec)\n",
            "I0701 22:34:27.601433 140494240802688 basic_session_run_hooks.py:260] loss = 2.8681548, step = 500 (78.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.26884\n",
            "I0701 22:35:46.412405 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.26884\n",
            "INFO:tensorflow:loss = 2.6948261, step = 600 (78.812 sec)\n",
            "I0701 22:35:46.413364 140494240802688 basic_session_run_hooks.py:260] loss = 2.6948261, step = 600 (78.812 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25136\n",
            "I0701 22:37:06.325464 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25136\n",
            "INFO:tensorflow:loss = 2.567058, step = 700 (79.914 sec)\n",
            "I0701 22:37:06.326875 140494240802688 basic_session_run_hooks.py:260] loss = 2.567058, step = 700 (79.914 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 726 into training/model.ckpt.\n",
            "I0701 22:37:25.837934 140494240802688 basic_session_run_hooks.py:606] Saving checkpoints for 726 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc6e0225ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0701 22:37:26.845172 140494240802688 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc6e0225ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6ef1cbc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0701 22:37:27.016865 140494240802688 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6ef1cbc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 22:37:27.546581 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:37:29.710002 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:37:29.788942 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:37:29.859200 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:37:29.929894 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:37:30.007738 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:37:30.081434 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0701 22:37:30.614898 140494240802688 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0701 22:37:30.818325 140494240802688 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 22:37:31.400788 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-01T22:37:31Z\n",
            "I0701 22:37:31.417886 140494240802688 evaluation.py:255] Starting evaluation at 2020-07-01T22:37:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0701 22:37:32.080470 140494240802688 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-01 22:37:32.081858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:37:32.082136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 22:37:32.082244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 22:37:32.082272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 22:37:32.082297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 22:37:32.082320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 22:37:32.082351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 22:37:32.082516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 22:37:32.082562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 22:37:32.082670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:37:32.083040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:37:32.083285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 22:37:32.083341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 22:37:32.083359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 22:37:32.083372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 22:37:32.083489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:37:32.083845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:37:32.084092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-726\n",
            "I0701 22:37:32.085144 140494240802688 saver.py:1284] Restoring parameters from training/model.ckpt-726\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0701 22:37:33.111950 140494240802688 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0701 22:37:33.260276 140494240802688 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 108 images.\n",
            "I0701 22:38:13.994842 140490698434304 coco_evaluation.py:237] Performing evaluation on 108 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0701 22:38:13.996781 140490698434304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0701 22:38:14.005992 140490698434304 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.77s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-01-22:38:18\n",
            "I0701 22:38:18.992959 140494240802688 evaluation.py:275] Finished evaluation at 2020-07-01-22:38:18\n",
            "INFO:tensorflow:Saving dict for global step 726: DetectionBoxes_Precision/mAP = 0.022637872, DetectionBoxes_Precision/mAP (large) = 0.25745064, DetectionBoxes_Precision/mAP (medium) = 0.049526375, DetectionBoxes_Precision/mAP (small) = 0.0008440579, DetectionBoxes_Precision/mAP@.50IOU = 0.07407994, DetectionBoxes_Precision/mAP@.75IOU = 0.0071650785, DetectionBoxes_Recall/AR@1 = 0.019857071, DetectionBoxes_Recall/AR@10 = 0.08079438, DetectionBoxes_Recall/AR@100 = 0.103585355, DetectionBoxes_Recall/AR@100 (large) = 0.45196566, DetectionBoxes_Recall/AR@100 (medium) = 0.23831338, DetectionBoxes_Recall/AR@100 (small) = 0.014205613, Loss/classification_loss = 0.37713757, Loss/localization_loss = 0.46544683, Loss/regularization_loss = 1.6901501, Loss/total_loss = 2.5327332, global_step = 726, learning_rate = 0.23013121, loss = 2.5327332\n",
            "I0701 22:38:18.993265 140494240802688 estimator.py:2049] Saving dict for global step 726: DetectionBoxes_Precision/mAP = 0.022637872, DetectionBoxes_Precision/mAP (large) = 0.25745064, DetectionBoxes_Precision/mAP (medium) = 0.049526375, DetectionBoxes_Precision/mAP (small) = 0.0008440579, DetectionBoxes_Precision/mAP@.50IOU = 0.07407994, DetectionBoxes_Precision/mAP@.75IOU = 0.0071650785, DetectionBoxes_Recall/AR@1 = 0.019857071, DetectionBoxes_Recall/AR@10 = 0.08079438, DetectionBoxes_Recall/AR@100 = 0.103585355, DetectionBoxes_Recall/AR@100 (large) = 0.45196566, DetectionBoxes_Recall/AR@100 (medium) = 0.23831338, DetectionBoxes_Recall/AR@100 (small) = 0.014205613, Loss/classification_loss = 0.37713757, Loss/localization_loss = 0.46544683, Loss/regularization_loss = 1.6901501, Loss/total_loss = 2.5327332, global_step = 726, learning_rate = 0.23013121, loss = 2.5327332\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 726: training/model.ckpt-726\n",
            "I0701 22:38:19.862540 140494240802688 estimator.py:2109] Saving 'checkpoint_path' summary for global step 726: training/model.ckpt-726\n",
            "INFO:tensorflow:global_step/sec: 0.743844\n",
            "I0701 22:39:20.762244 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 0.743844\n",
            "INFO:tensorflow:loss = 2.436434, step = 800 (134.437 sec)\n",
            "I0701 22:39:20.763680 140494240802688 basic_session_run_hooks.py:260] loss = 2.436434, step = 800 (134.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24449\n",
            "I0701 22:40:41.116571 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.24449\n",
            "INFO:tensorflow:loss = 2.300065, step = 900 (80.354 sec)\n",
            "I0701 22:40:41.117854 140494240802688 basic_session_run_hooks.py:260] loss = 2.300065, step = 900 (80.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24352\n",
            "I0701 22:42:01.533318 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.24352\n",
            "INFO:tensorflow:loss = 2.3320682, step = 1000 (80.417 sec)\n",
            "I0701 22:42:01.534579 140494240802688 basic_session_run_hooks.py:260] loss = 2.3320682, step = 1000 (80.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25991\n",
            "I0701 22:43:20.903819 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25991\n",
            "INFO:tensorflow:loss = 2.2881174, step = 1100 (79.371 sec)\n",
            "I0701 22:43:20.905186 140494240802688 basic_session_run_hooks.py:260] loss = 2.2881174, step = 1100 (79.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.27707\n",
            "I0701 22:44:39.207842 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.27707\n",
            "INFO:tensorflow:loss = 2.2322426, step = 1200 (78.304 sec)\n",
            "I0701 22:44:39.209179 140494240802688 basic_session_run_hooks.py:260] loss = 2.2322426, step = 1200 (78.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25186\n",
            "I0701 22:45:59.088925 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25186\n",
            "INFO:tensorflow:loss = 2.1610866, step = 1300 (79.881 sec)\n",
            "I0701 22:45:59.089809 140494240802688 basic_session_run_hooks.py:260] loss = 2.1610866, step = 1300 (79.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2624\n",
            "I0701 22:47:18.302952 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.2624\n",
            "INFO:tensorflow:loss = 2.216599, step = 1400 (79.214 sec)\n",
            "I0701 22:47:18.304002 140494240802688 basic_session_run_hooks.py:260] loss = 2.216599, step = 1400 (79.214 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1411 into training/model.ckpt.\n",
            "I0701 22:47:26.281255 140494240802688 basic_session_run_hooks.py:606] Saving checkpoints for 1411 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc56ac4a438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0701 22:47:27.253606 140494240802688 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc56ac4a438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6e01f5d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0701 22:47:27.413843 140494240802688 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6e01f5d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 22:47:27.886082 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:47:30.103778 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:47:30.180011 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:47:30.260634 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:47:30.336826 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:47:30.409872 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:47:30.481739 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 22:47:32.005419 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-01T22:47:32Z\n",
            "I0701 22:47:32.024020 140494240802688 evaluation.py:255] Starting evaluation at 2020-07-01T22:47:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0701 22:47:32.545706 140494240802688 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-01 22:47:32.546440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:47:32.546815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 22:47:32.546926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 22:47:32.546958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 22:47:32.546982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 22:47:32.547006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 22:47:32.547030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 22:47:32.547050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 22:47:32.547077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 22:47:32.547160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:47:32.547437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:47:32.547647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 22:47:32.547713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 22:47:32.547727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 22:47:32.547736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 22:47:32.547840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:47:32.548126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:47:32.548350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1411\n",
            "I0701 22:47:32.549484 140494240802688 saver.py:1284] Restoring parameters from training/model.ckpt-1411\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0701 22:47:33.685334 140494240802688 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0701 22:47:33.835433 140494240802688 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 108 images.\n",
            "I0701 22:48:17.803094 140490698434304 coco_evaluation.py:237] Performing evaluation on 108 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0701 22:48:17.804548 140490698434304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0701 22:48:17.818532 140490698434304 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.65s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-01-22:48:22\n",
            "I0701 22:48:22.685940 140494240802688 evaluation.py:275] Finished evaluation at 2020-07-01-22:48:22\n",
            "INFO:tensorflow:Saving dict for global step 1411: DetectionBoxes_Precision/mAP = 0.032619826, DetectionBoxes_Precision/mAP (large) = 0.23197666, DetectionBoxes_Precision/mAP (medium) = 0.08116692, DetectionBoxes_Precision/mAP (small) = 0.0039348314, DetectionBoxes_Precision/mAP@.50IOU = 0.09683683, DetectionBoxes_Precision/mAP@.75IOU = 0.0099836355, DetectionBoxes_Recall/AR@1 = 0.018565914, DetectionBoxes_Recall/AR@10 = 0.07765878, DetectionBoxes_Recall/AR@100 = 0.09791904, DetectionBoxes_Recall/AR@100 (large) = 0.38117388, DetectionBoxes_Recall/AR@100 (medium) = 0.20511872, DetectionBoxes_Recall/AR@100 (small) = 0.026728041, Loss/classification_loss = 0.6437795, Loss/localization_loss = 0.45743868, Loss/regularization_loss = 1.4657546, Loss/total_loss = 2.5669737, global_step = 1411, learning_rate = 0.3214657, loss = 2.5669737\n",
            "I0701 22:48:22.686239 140494240802688 estimator.py:2049] Saving dict for global step 1411: DetectionBoxes_Precision/mAP = 0.032619826, DetectionBoxes_Precision/mAP (large) = 0.23197666, DetectionBoxes_Precision/mAP (medium) = 0.08116692, DetectionBoxes_Precision/mAP (small) = 0.0039348314, DetectionBoxes_Precision/mAP@.50IOU = 0.09683683, DetectionBoxes_Precision/mAP@.75IOU = 0.0099836355, DetectionBoxes_Recall/AR@1 = 0.018565914, DetectionBoxes_Recall/AR@10 = 0.07765878, DetectionBoxes_Recall/AR@100 = 0.09791904, DetectionBoxes_Recall/AR@100 (large) = 0.38117388, DetectionBoxes_Recall/AR@100 (medium) = 0.20511872, DetectionBoxes_Recall/AR@100 (small) = 0.026728041, Loss/classification_loss = 0.6437795, Loss/localization_loss = 0.45743868, Loss/regularization_loss = 1.4657546, Loss/total_loss = 2.5669737, global_step = 1411, learning_rate = 0.3214657, loss = 2.5669737\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1411: training/model.ckpt-1411\n",
            "I0701 22:48:22.690798 140494240802688 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1411: training/model.ckpt-1411\n",
            "INFO:tensorflow:global_step/sec: 0.735025\n",
            "I0701 22:49:34.352818 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 0.735025\n",
            "INFO:tensorflow:loss = 2.0220582, step = 1500 (136.050 sec)\n",
            "I0701 22:49:34.354247 140494240802688 basic_session_run_hooks.py:260] loss = 2.0220582, step = 1500 (136.050 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23895\n",
            "I0701 22:50:55.066346 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.23895\n",
            "INFO:tensorflow:loss = 1.9955754, step = 1600 (80.713 sec)\n",
            "I0701 22:50:55.067609 140494240802688 basic_session_run_hooks.py:260] loss = 1.9955754, step = 1600 (80.713 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2372\n",
            "I0701 22:52:15.894342 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.2372\n",
            "INFO:tensorflow:loss = 2.3082461, step = 1700 (80.828 sec)\n",
            "I0701 22:52:15.895619 140494240802688 basic_session_run_hooks.py:260] loss = 2.3082461, step = 1700 (80.828 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24454\n",
            "I0701 22:53:36.245259 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.24454\n",
            "INFO:tensorflow:loss = 1.9709283, step = 1800 (80.351 sec)\n",
            "I0701 22:53:36.246570 140494240802688 basic_session_run_hooks.py:260] loss = 1.9709283, step = 1800 (80.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24544\n",
            "I0701 22:54:56.537941 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.24544\n",
            "INFO:tensorflow:loss = 1.8028166, step = 1900 (80.352 sec)\n",
            "I0701 22:54:56.598825 140494240802688 basic_session_run_hooks.py:260] loss = 1.8028166, step = 1900 (80.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2509\n",
            "I0701 22:56:16.480062 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.2509\n",
            "INFO:tensorflow:loss = 1.7432256, step = 2000 (79.883 sec)\n",
            "I0701 22:56:16.481378 140494240802688 basic_session_run_hooks.py:260] loss = 1.7432256, step = 2000 (79.883 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2088 into training/model.ckpt.\n",
            "I0701 22:57:26.493816 140494240802688 basic_session_run_hooks.py:606] Saving checkpoints for 2088 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc6e01df438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0701 22:57:27.565846 140494240802688 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc6e01df438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6803cdea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0701 22:57:27.744977 140494240802688 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6803cdea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 22:57:28.258280 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:57:30.496552 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:57:30.572451 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:57:30.650505 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:57:30.727438 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:57:30.811752 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 22:57:30.890283 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 22:57:32.264211 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-01T22:57:32Z\n",
            "I0701 22:57:32.281759 140494240802688 evaluation.py:255] Starting evaluation at 2020-07-01T22:57:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0701 22:57:32.788119 140494240802688 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-01 22:57:32.788865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:57:32.789244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 22:57:32.789371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 22:57:32.789417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 22:57:32.789444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 22:57:32.789473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 22:57:32.789509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 22:57:32.789563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 22:57:32.789594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 22:57:32.789716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:57:32.790036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:57:32.790287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 22:57:32.790418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 22:57:32.790436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 22:57:32.790447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 22:57:32.790548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:57:32.790885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 22:57:32.791145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2088\n",
            "I0701 22:57:32.792143 140494240802688 saver.py:1284] Restoring parameters from training/model.ckpt-2088\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0701 22:57:33.992023 140494240802688 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0701 22:57:34.145815 140494240802688 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 108 images.\n",
            "I0701 22:58:23.862672 140492149139200 coco_evaluation.py:237] Performing evaluation on 108 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0701 22:58:23.864451 140492149139200 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0701 22:58:23.869243 140492149139200 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.110\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-01-22:58:28\n",
            "I0701 22:58:28.754773 140494240802688 evaluation.py:275] Finished evaluation at 2020-07-01-22:58:28\n",
            "INFO:tensorflow:Saving dict for global step 2088: DetectionBoxes_Precision/mAP = 0.110269725, DetectionBoxes_Precision/mAP (large) = 0.5330194, DetectionBoxes_Precision/mAP (medium) = 0.26125714, DetectionBoxes_Precision/mAP (small) = 0.011949826, DetectionBoxes_Precision/mAP@.50IOU = 0.2708806, DetectionBoxes_Precision/mAP@.75IOU = 0.06968929, DetectionBoxes_Recall/AR@1 = 0.0467256, DetectionBoxes_Recall/AR@10 = 0.16510007, DetectionBoxes_Recall/AR@100 = 0.19863585, DetectionBoxes_Recall/AR@100 (large) = 0.6101606, DetectionBoxes_Recall/AR@100 (medium) = 0.40848887, DetectionBoxes_Recall/AR@100 (small) = 0.06870942, Loss/classification_loss = 0.22790705, Loss/localization_loss = 0.2423171, Loss/regularization_loss = 1.2306119, Loss/total_loss = 1.7008352, global_step = 2088, learning_rate = 0.39999995, loss = 1.7008352\n",
            "I0701 22:58:28.755082 140494240802688 estimator.py:2049] Saving dict for global step 2088: DetectionBoxes_Precision/mAP = 0.110269725, DetectionBoxes_Precision/mAP (large) = 0.5330194, DetectionBoxes_Precision/mAP (medium) = 0.26125714, DetectionBoxes_Precision/mAP (small) = 0.011949826, DetectionBoxes_Precision/mAP@.50IOU = 0.2708806, DetectionBoxes_Precision/mAP@.75IOU = 0.06968929, DetectionBoxes_Recall/AR@1 = 0.0467256, DetectionBoxes_Recall/AR@10 = 0.16510007, DetectionBoxes_Recall/AR@100 = 0.19863585, DetectionBoxes_Recall/AR@100 (large) = 0.6101606, DetectionBoxes_Recall/AR@100 (medium) = 0.40848887, DetectionBoxes_Recall/AR@100 (small) = 0.06870942, Loss/classification_loss = 0.22790705, Loss/localization_loss = 0.2423171, Loss/regularization_loss = 1.2306119, Loss/total_loss = 1.7008352, global_step = 2088, learning_rate = 0.39999995, loss = 1.7008352\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2088: training/model.ckpt-2088\n",
            "I0701 22:58:28.761075 140494240802688 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2088: training/model.ckpt-2088\n",
            "INFO:tensorflow:global_step/sec: 0.700238\n",
            "I0701 22:58:39.288677 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 0.700238\n",
            "INFO:tensorflow:loss = 1.720211, step = 2100 (142.810 sec)\n",
            "I0701 22:58:39.291292 140494240802688 basic_session_run_hooks.py:260] loss = 1.720211, step = 2100 (142.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25556\n",
            "I0701 22:59:58.934551 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25556\n",
            "INFO:tensorflow:loss = 1.6926064, step = 2200 (79.644 sec)\n",
            "I0701 22:59:58.935595 140494240802688 basic_session_run_hooks.py:260] loss = 1.6926064, step = 2200 (79.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25146\n",
            "I0701 23:01:18.841208 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25146\n",
            "INFO:tensorflow:loss = 1.6474004, step = 2300 (79.907 sec)\n",
            "I0701 23:01:18.842241 140494240802688 basic_session_run_hooks.py:260] loss = 1.6474004, step = 2300 (79.907 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25372\n",
            "I0701 23:02:38.603817 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.25372\n",
            "INFO:tensorflow:loss = 1.5490196, step = 2400 (79.763 sec)\n",
            "I0701 23:02:38.605043 140494240802688 basic_session_run_hooks.py:260] loss = 1.5490196, step = 2400 (79.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24586\n",
            "I0701 23:03:58.869845 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.24586\n",
            "INFO:tensorflow:loss = 1.5262448, step = 2500 (80.266 sec)\n",
            "I0701 23:03:58.870804 140494240802688 basic_session_run_hooks.py:260] loss = 1.5262448, step = 2500 (80.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2624\n",
            "I0701 23:05:18.083832 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.2624\n",
            "INFO:tensorflow:loss = 1.5528204, step = 2600 (79.214 sec)\n",
            "I0701 23:05:18.085105 140494240802688 basic_session_run_hooks.py:260] loss = 1.5528204, step = 2600 (79.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2549\n",
            "I0701 23:06:37.771626 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.2549\n",
            "INFO:tensorflow:loss = 1.3910987, step = 2700 (79.688 sec)\n",
            "I0701 23:06:37.772800 140494240802688 basic_session_run_hooks.py:260] loss = 1.3910987, step = 2700 (79.688 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2763 into training/model.ckpt.\n",
            "I0701 23:07:26.865160 140494240802688 basic_session_run_hooks.py:606] Saving checkpoints for 2763 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc68049e0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0701 23:07:27.957380 140494240802688 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc68049e0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6843368c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0701 23:07:28.131268 140494240802688 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc6843368c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 23:07:28.632724 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:07:30.835498 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:07:30.914425 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:07:30.986988 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:07:31.060680 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:07:31.139536 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:07:31.215004 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 23:07:32.516301 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-01T23:07:32Z\n",
            "I0701 23:07:32.533910 140494240802688 evaluation.py:255] Starting evaluation at 2020-07-01T23:07:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0701 23:07:33.036413 140494240802688 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-01 23:07:33.037133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:07:33.037457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:07:33.037564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:07:33.037592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:07:33.037612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:07:33.037641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:07:33.037658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:07:33.037678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:07:33.037715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:07:33.037804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:07:33.038102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:07:33.038328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:07:33.038377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 23:07:33.038398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 23:07:33.038407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 23:07:33.038499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:07:33.038794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:07:33.039027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2763\n",
            "I0701 23:07:33.040131 140494240802688 saver.py:1284] Restoring parameters from training/model.ckpt-2763\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0701 23:07:34.207929 140494240802688 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0701 23:07:34.349900 140494240802688 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 108 images.\n",
            "I0701 23:08:26.122022 140490698434304 coco_evaluation.py:237] Performing evaluation on 108 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0701 23:08:26.124564 140490698434304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0701 23:08:26.133733 140490698434304 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-01-23:08:31\n",
            "I0701 23:08:31.102598 140494240802688 evaluation.py:275] Finished evaluation at 2020-07-01-23:08:31\n",
            "INFO:tensorflow:Saving dict for global step 2763: DetectionBoxes_Precision/mAP = 0.11472897, DetectionBoxes_Precision/mAP (large) = 0.39203033, DetectionBoxes_Precision/mAP (medium) = 0.25907108, DetectionBoxes_Precision/mAP (small) = 0.02154393, DetectionBoxes_Precision/mAP@.50IOU = 0.34355244, DetectionBoxes_Precision/mAP@.75IOU = 0.021856528, DetectionBoxes_Recall/AR@1 = 0.03990493, DetectionBoxes_Recall/AR@10 = 0.16411565, DetectionBoxes_Recall/AR@100 = 0.18007226, DetectionBoxes_Recall/AR@100 (large) = 0.42342192, DetectionBoxes_Recall/AR@100 (medium) = 0.34986094, DetectionBoxes_Recall/AR@100 (small) = 0.08129165, Loss/classification_loss = 0.16212972, Loss/localization_loss = 0.23260826, Loss/regularization_loss = 1.0050638, Loss/total_loss = 1.3998007, global_step = 2763, learning_rate = 0.39999637, loss = 1.3998007\n",
            "I0701 23:08:31.102930 140494240802688 estimator.py:2049] Saving dict for global step 2763: DetectionBoxes_Precision/mAP = 0.11472897, DetectionBoxes_Precision/mAP (large) = 0.39203033, DetectionBoxes_Precision/mAP (medium) = 0.25907108, DetectionBoxes_Precision/mAP (small) = 0.02154393, DetectionBoxes_Precision/mAP@.50IOU = 0.34355244, DetectionBoxes_Precision/mAP@.75IOU = 0.021856528, DetectionBoxes_Recall/AR@1 = 0.03990493, DetectionBoxes_Recall/AR@10 = 0.16411565, DetectionBoxes_Recall/AR@100 = 0.18007226, DetectionBoxes_Recall/AR@100 (large) = 0.42342192, DetectionBoxes_Recall/AR@100 (medium) = 0.34986094, DetectionBoxes_Recall/AR@100 (small) = 0.08129165, Loss/classification_loss = 0.16212972, Loss/localization_loss = 0.23260826, Loss/regularization_loss = 1.0050638, Loss/total_loss = 1.3998007, global_step = 2763, learning_rate = 0.39999637, loss = 1.3998007\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2763: training/model.ckpt-2763\n",
            "I0701 23:08:31.107378 140494240802688 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2763: training/model.ckpt-2763\n",
            "INFO:tensorflow:global_step/sec: 0.696605\n",
            "I0701 23:09:01.324951 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 0.696605\n",
            "INFO:tensorflow:loss = 1.4039762, step = 2800 (143.553 sec)\n",
            "I0701 23:09:01.326139 140494240802688 basic_session_run_hooks.py:260] loss = 1.4039762, step = 2800 (143.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.26864\n",
            "I0701 23:10:20.149630 140494240802688 basic_session_run_hooks.py:692] global_step/sec: 1.26864\n",
            "INFO:tensorflow:loss = 1.2983716, step = 2900 (78.825 sec)\n",
            "I0701 23:10:20.150976 140494240802688 basic_session_run_hooks.py:260] loss = 1.2983716, step = 2900 (78.825 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into training/model.ckpt.\n",
            "I0701 23:11:40.668549 140494240802688 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0701 23:11:40.708898 140494240802688 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0701 23:11:41.628839 140494240802688 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc56e2f14e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0701 23:11:41.687777 140494240802688 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc56e2f14e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc56e454f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0701 23:11:41.858488 140494240802688 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc56e454f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 23:11:42.351318 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:11:44.490077 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:11:44.561710 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:11:44.632153 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:11:44.702409 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:11:44.775087 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:11:44.846030 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 23:11:46.070916 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-01T23:11:46Z\n",
            "I0701 23:11:46.091794 140494240802688 evaluation.py:255] Starting evaluation at 2020-07-01T23:11:46Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0701 23:11:46.596359 140494240802688 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-01 23:11:46.597057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:11:46.597389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:11:46.597498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:11:46.597528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:11:46.597551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:11:46.597577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:11:46.597598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:11:46.597617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:11:46.597637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:11:46.597740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:11:46.598098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:11:46.598361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:11:46.598409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 23:11:46.598424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 23:11:46.598434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 23:11:46.598532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:11:46.598843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:11:46.599078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3000\n",
            "I0701 23:11:46.600196 140494240802688 saver.py:1284] Restoring parameters from training/model.ckpt-3000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0701 23:11:47.681041 140494240802688 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0701 23:11:47.823124 140494240802688 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 108 images.\n",
            "I0701 23:12:39.049134 140490698434304 coco_evaluation.py:237] Performing evaluation on 108 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0701 23:12:39.051956 140490698434304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0701 23:12:39.060739 140490698434304 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-01-23:12:43\n",
            "I0701 23:12:43.915193 140494240802688 evaluation.py:275] Finished evaluation at 2020-07-01-23:12:43\n",
            "INFO:tensorflow:Saving dict for global step 3000: DetectionBoxes_Precision/mAP = 0.1276408, DetectionBoxes_Precision/mAP (large) = 0.6035882, DetectionBoxes_Precision/mAP (medium) = 0.28426936, DetectionBoxes_Precision/mAP (small) = 0.025742298, DetectionBoxes_Precision/mAP@.50IOU = 0.33747616, DetectionBoxes_Precision/mAP@.75IOU = 0.06869978, DetectionBoxes_Recall/AR@1 = 0.047330495, DetectionBoxes_Recall/AR@10 = 0.1872831, DetectionBoxes_Recall/AR@100 = 0.20121983, DetectionBoxes_Recall/AR@100 (large) = 0.6670266, DetectionBoxes_Recall/AR@100 (medium) = 0.4003195, DetectionBoxes_Recall/AR@100 (small) = 0.07286078, Loss/classification_loss = 0.1333176, Loss/localization_loss = 0.20671473, Loss/regularization_loss = 0.9360103, Loss/total_loss = 1.2760421, global_step = 3000, learning_rate = 0.39999375, loss = 1.2760421\n",
            "I0701 23:12:43.915455 140494240802688 estimator.py:2049] Saving dict for global step 3000: DetectionBoxes_Precision/mAP = 0.1276408, DetectionBoxes_Precision/mAP (large) = 0.6035882, DetectionBoxes_Precision/mAP (medium) = 0.28426936, DetectionBoxes_Precision/mAP (small) = 0.025742298, DetectionBoxes_Precision/mAP@.50IOU = 0.33747616, DetectionBoxes_Precision/mAP@.75IOU = 0.06869978, DetectionBoxes_Recall/AR@1 = 0.047330495, DetectionBoxes_Recall/AR@10 = 0.1872831, DetectionBoxes_Recall/AR@100 = 0.20121983, DetectionBoxes_Recall/AR@100 (large) = 0.6670266, DetectionBoxes_Recall/AR@100 (medium) = 0.4003195, DetectionBoxes_Recall/AR@100 (small) = 0.07286078, Loss/classification_loss = 0.1333176, Loss/localization_loss = 0.20671473, Loss/regularization_loss = 0.9360103, Loss/total_loss = 1.2760421, global_step = 3000, learning_rate = 0.39999375, loss = 1.2760421\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: training/model.ckpt-3000\n",
            "I0701 23:12:43.920902 140494240802688 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3000: training/model.ckpt-3000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0701 23:12:43.921633 140494240802688 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0701 23:12:44.159000 140494240802688 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:12:46.670142 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:12:46.743781 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:12:46.817033 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:12:46.894332 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:12:46.979782 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:12:47.054494 140494240802688 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0701 23:12:47.629094 140494240802688 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0701 23:12:47.629396 140494240802688 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0701 23:12:47.630116 140494240802688 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0701 23:12:47.630252 140494240802688 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0701 23:12:47.630346 140494240802688 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0701 23:12:47.630442 140494240802688 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0701 23:12:47.630507 140494240802688 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-07-01 23:12:47.631103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:12:47.631430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:12:47.631549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:12:47.631583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:12:47.631607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:12:47.631646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:12:47.631671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:12:47.631712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:12:47.631739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:12:47.631833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:12:47.632177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:12:47.632448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:12:47.632498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 23:12:47.632513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 23:12:47.632524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 23:12:47.632637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:12:47.632975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:12:47.633222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3000\n",
            "I0701 23:12:47.636343 140494240802688 saver.py:1284] Restoring parameters from training/model.ckpt-3000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0701 23:12:48.206514 140494240802688 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0701 23:12:48.206744 140494240802688 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1593645163'/saved_model.pb\n",
            "I0701 23:12:49.070217 140494240802688 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1593645163'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 1.259885.\n",
            "I0701 23:12:49.427916 140494240802688 estimator.py:371] Loss for final step: 1.259885.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e73810f5-6179-4077-8505-17335ec26466"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1593642433.1e1ee265e4c0\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-1411.data-00000-of-00001\n",
            "model.ckpt-1411.index\n",
            "model.ckpt-1411.meta\n",
            "model.ckpt-2088.data-00000-of-00001\n",
            "model.ckpt-2088.index\n",
            "model.ckpt-2088.meta\n",
            "model.ckpt-2763.data-00000-of-00001\n",
            "model.ckpt-2763.index\n",
            "model.ckpt-2763.meta\n",
            "model.ckpt-3000.data-00000-of-00001\n",
            "model.ckpt-3000.index\n",
            "model.ckpt-3000.meta\n",
            "model.ckpt-726.data-00000-of-00001\n",
            "model.ckpt-726.index\n",
            "model.ckpt-726.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4158e0b1-7bcc-461b-a8cf-375834c58b2a"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0701 23:16:53.794041 139835808991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:16:56.123268 139835808991104 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:16:56.211974 139835808991104 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:16:56.301324 139835808991104 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:16:56.393064 139835808991104 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:16:56.480792 139835808991104 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0701 23:16:56.576062 139835808991104 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:1108: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0701 23:16:56.843408 139835808991104 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:1108: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0701 23:16:57.051893 139835808991104 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0701 23:16:57.055400 139835808991104 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0701 23:16:57.056007 139835808991104 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "215 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/2.17m params)\n",
            "  BoxPredictor_0 (--/26.23k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/8.08k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x672x12, 8.06k/8.06k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/6.05k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x672x1, 6.05k/6.05k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/6.06k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (9, 9/9 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x672x9, 6.05k/6.05k params)\n",
            "    BoxPredictor_0/ClassPredictor_depthwise (--/6.05k params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x672x1, 6.05k/6.05k params)\n",
            "  BoxPredictor_1 (--/28.84k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/11.54k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x480x24, 11.52k/11.52k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/4.32k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x480x1, 4.32k/4.32k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/8.66k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (18, 18/18 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x480x18, 8.64k/8.64k params)\n",
            "    BoxPredictor_1/ClassPredictor_depthwise (--/4.32k params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x480x1, 4.32k/4.32k params)\n",
            "  BoxPredictor_2 (--/30.76k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/9.23k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (18, 18/18 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n",
            "    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "  BoxPredictor_3 (--/15.40k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/4.63k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (18, 18/18 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n",
            "    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_4 (--/15.40k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/4.63k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (18, 18/18 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n",
            "    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_5 (--/7.72k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/2.32k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (18, 18/18 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x18, 2.30k/2.30k params)\n",
            "    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "  FeatureExtractor (--/2.05m params)\n",
            "    FeatureExtractor/MobilenetV3 (--/2.05m params)\n",
            "      FeatureExtractor/MobilenetV3/Conv (--/432 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/weights (3x3x3x16, 432/432 params)\n",
            "      FeatureExtractor/MobilenetV3/Conv_1 (--/38.40k params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/weights (1x1x80x480, 38.40k/38.40k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv (--/400 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/depthwise (--/144 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/depthwise_weights (3x3x16x1, 144/144 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/project (--/256 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/weights (1x1x16x16, 256/256 params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_1 (--/3.14k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise (--/576 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/expand (--/1.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/weights (1x1x16x64, 1.02k/1.02k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/project (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/weights (1x1x64x24, 1.54k/1.54k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_10 (--/212.28k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise (--/4.32k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/depthwise_weights (3x3x480x1, 4.32k/4.32k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/expand (--/38.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/weights (1x1x80x480, 38.40k/38.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/project (--/53.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/weights (1x1x480x112, 53.76k/53.76k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite (--/115.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv (--/57.72k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/weights (1x1x480x120, 57.60k/57.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1 (--/58.08k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/biases (480, 480/480 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/weights (1x1x120x480, 57.60k/57.60k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_11 (--/383.21k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_11/depthwise (--/6.05k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/depthwise/depthwise_weights (3x3x672x1, 6.05k/6.05k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_11/expand (--/75.26k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/expand/weights (1x1x112x672, 75.26k/75.26k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_11/project (--/75.26k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/project/weights (1x1x672x112, 75.26k/75.26k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite (--/226.63k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv (--/113.06k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv/biases (168, 168/168 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv/weights (1x1x672x168, 112.90k/112.90k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv_1 (--/113.57k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv_1/biases (672, 672/672 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv_1/weights (1x1x168x672, 112.90k/112.90k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_12 (--/372.46k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_12/depthwise (--/16.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/depthwise/depthwise_weights (5x5x672x1, 16.80k/16.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_12/expand (--/75.26k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/expand/weights (1x1x112x672, 75.26k/75.26k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_12/project (--/53.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/project/weights (1x1x672x80, 53.76k/53.76k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite (--/226.63k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv (--/113.06k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv/biases (168, 168/168 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv/weights (1x1x672x168, 112.90k/112.90k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv_1 (--/113.57k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv_1/biases (672, 672/672 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv_1/weights (1x1x168x672, 112.90k/112.90k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_13 (--/204.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_13/depthwise (--/12.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/depthwise/depthwise_weights (5x5x480x1, 12.00k/12.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_13/expand (--/38.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/expand/weights (1x1x80x480, 38.40k/38.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_13/project (--/38.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/project/weights (1x1x480x80, 38.40k/38.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite (--/115.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv (--/57.72k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv/weights (1x1x480x120, 57.60k/57.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv_1 (--/58.08k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv_1/biases (480, 480/480 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv_1/weights (1x1x120x480, 57.60k/57.60k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_14 (--/204.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_14/depthwise (--/12.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/depthwise/depthwise_weights (5x5x480x1, 12.00k/12.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_14/expand (--/38.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/expand/weights (1x1x80x480, 38.40k/38.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_14/project (--/38.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/project/weights (1x1x480x80, 38.40k/38.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite (--/115.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv (--/57.72k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv/weights (1x1x480x120, 57.60k/57.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv_1 (--/58.08k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv_1/biases (480, 480/480 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv_1/weights (1x1x120x480, 57.60k/57.60k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_2 (--/4.10k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise (--/648 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/depthwise_weights (3x3x72x1, 648/648 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/expand (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/weights (1x1x24x72, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/project (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/weights (1x1x72x24, 1.73k/1.73k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_3 (--/9.96k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise (--/1.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/depthwise_weights (5x5x72x1, 1.80k/1.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/expand (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/weights (1x1x24x72, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/project (--/2.88k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/weights (1x1x72x40, 2.88k/2.88k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite (--/3.55k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv (--/1.75k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/biases (24, 24/24 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/weights (1x1x72x24, 1.73k/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1 (--/1.80k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/weights (1x1x24x72, 1.73k/1.73k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_4 (--/20.43k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise (--/3.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/expand (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/weights (1x1x40x120, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/project (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/weights (1x1x120x40, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite (--/7.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv (--/3.87k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/biases (32, 32/32 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1 (--/3.96k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_5 (--/20.43k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise (--/3.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/expand (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/weights (1x1x40x120, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/project (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/weights (1x1x120x40, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite (--/7.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv (--/3.87k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/biases (32, 32/32 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1 (--/3.96k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_6 (--/30.96k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise (--/2.16k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/depthwise_weights (3x3x240x1, 2.16k/2.16k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/project (--/19.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/weights (1x1x240x80, 19.20k/19.20k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_7 (--/33.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise (--/1.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/depthwise_weights (3x3x200x1, 1.80k/1.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/expand (--/16.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/weights (1x1x80x200, 16.00k/16.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/project (--/16.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/weights (1x1x200x80, 16.00k/16.00k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_8 (--/31.10k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise (--/1.66k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/depthwise_weights (3x3x184x1, 1.66k/1.66k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/expand (--/14.72k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/weights (1x1x80x184, 14.72k/14.72k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/project (--/14.72k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/weights (1x1x184x80, 14.72k/14.72k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_9 (--/31.10k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise (--/1.66k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/depthwise_weights (3x3x184x1, 1.66k/1.66k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/expand (--/14.72k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/weights (1x1x80x184, 14.72k/14.72k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/project (--/14.72k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/weights (1x1x184x80, 14.72k/14.72k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_2_1x1_256 (--/122.88k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_2_1x1_256/weights (1x1x480x256, 122.88k/122.88k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "\n",
            "======================End of Report==========================\n",
            "215 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/19.29k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_2 (800/800 flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/mul (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/GreaterEqual (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_3 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_2 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_3 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_2 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_1 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_3 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_2 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_1 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_2 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub_1 (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub (200/200 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Sum (199/199 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_1 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_1 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul (100/100 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2020-07-01 23:16:59.137932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-01 23:16:59.141913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.142286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:16:59.142580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:16:59.144147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:16:59.145826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:16:59.146147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:16:59.148048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:16:59.149244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:16:59.153140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:16:59.153291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.153721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.154030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:16:59.154344: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-01 23:16:59.159447: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2020-07-01 23:16:59.159632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2544bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-01 23:16:59.159660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-01 23:16:59.235512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.235992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2544d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-01 23:16:59.236025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-07-01 23:16:59.236196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.236538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:16:59.236604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:16:59.236631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:16:59.236655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:16:59.236675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:16:59.236754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:16:59.236780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:16:59.236801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:16:59.236880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.237273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.237610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:16:59.237686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:16:59.238779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 23:16:59.238807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 23:16:59.238820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 23:16:59.238939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.239306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:16:59.239617: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-01 23:16:59.239656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1000\n",
            "I0701 23:16:59.241495 139835808991104 saver.py:1284] Restoring parameters from training/model.ckpt-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0701 23:17:01.387623 139835808991104 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-07-01 23:17:02.051222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:02.051687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:17:02.051810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:17:02.051836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:17:02.051859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:17:02.051879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:17:02.051899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:17:02.051918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:17:02.051938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:17:02.052034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:02.052420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:02.052739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:17:02.052780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 23:17:02.052796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 23:17:02.052806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 23:17:02.052910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:02.053314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:02.053628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1000\n",
            "I0701 23:17:02.054768 139835808991104 saver.py:1284] Restoring parameters from training/model.ckpt-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0701 23:17:02.740585 139835808991104 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0701 23:17:02.740867 139835808991104 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 406 variables.\n",
            "I0701 23:17:03.144270 139835808991104 graph_util_impl.py:334] Froze 406 variables.\n",
            "INFO:tensorflow:Converted 406 variables to const ops.\n",
            "I0701 23:17:03.209994 139835808991104 graph_util_impl.py:394] Converted 406 variables to const ops.\n",
            "2020-07-01 23:17:03.326933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:03.327350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-01 23:17:03.327445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-01 23:17:03.327474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-01 23:17:03.327497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-01 23:17:03.327523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-01 23:17:03.327543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-01 23:17:03.327562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-01 23:17:03.327583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-01 23:17:03.327669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:03.328039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:03.328337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-01 23:17:03.328378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-01 23:17:03.328392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-01 23:17:03.328401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-01 23:17:03.328499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:03.328860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-01 23:17:03.329160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0701 23:17:03.708162 139835808991104 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0701 23:17:03.708883 139835808991104 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0701 23:17:03.709022 139835808991104 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I0701 23:17:03.948243 139835808991104 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I0701 23:17:03.969273 139835808991104 config_util.py:254] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3c448364-0301-4c7c-d19e-50a155ec2647"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.pb` file, the `label_map.pbtxt` file and the modified `pipline` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b02e638f-b532-4bec-ea22-25dad38b760c"
      },
      "source": [
        "!ls -alh {pb_fname}\n",
        "\n",
        "# .pb download\n",
        "from google.colab import files\n",
        "files.download(pb_fname)\n",
        "\n",
        "# label_map.pbtxt download\n",
        "files.download(label_map_pbtxt_fname)\n",
        "\n",
        "# modified Pipeline download\n",
        "# If you plan to use OpenVINO toolkit to convert the .pb file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)\n",
        "files.download(pipeline_fname)\n",
        "\n",
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 9.2M Jul  1 23:17 /content/models/research/object_detection/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_eee2b9b5-3953-4efd-949f-426bc0a3731b\", \"frozen_inference_graph.pb\", 9552248)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4bec74a6-f539-41b2-850c-2ff48c58d62d\", \"label_map.pbtxt\", 67)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e6994687-15df-410e-adb4-36fedbedb2a6\", \"ssdlite_mobilenet_v3_large_320x320_coco.config\", 4706)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7",
        "colab_type": "text"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `object_detection_demo/test` directory.<br>\n",
        "Add your test image here and enjoy ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "120d22e7-1345-4582-e8fa-d25d5fa028c1"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/object_detection_demo/test/1584913467_Camera0_visible.png', '/content/object_detection_demo/test/1584913468_Camera0_visible.png', '/content/object_detection_demo/test/1584912619_Camera1_visible.png', '/content/object_detection_demo/test/1584913466_Camera1_visible.png', '/content/object_detection_demo/test/1584913465_Camera0_visible.png', '/content/object_detection_demo/test/1584913464_Camera0_visible.png', '/content/object_detection_demo/test/1584912701_Camera0_visible.png', '/content/object_detection_demo/test/1584913467_Camera1_visible.png', '/content/object_detection_demo/test/1584913465_Camera1_visible.png', '/content/object_detection_demo/test/1584913466_Camera0_visible.png', '/content/object_detection_demo/test/1584912620_Camera0_visible.png', '/content/object_detection_demo/test/1584913464_Camera1_visible.png', '/content/object_detection_demo/test/1584912700_Camera1_visible.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef7d46a7-6466-4a6b-c3b0-d3f14832612b"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}